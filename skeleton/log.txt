mkdir classes; javac -classpath /opt/hadoop-2.7.2/share/hadoop/common/*:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/*:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/*:/opt/hadoop-2.7.2/share/hadoop/mapreduce/*:./  -d classes src/*.java; jar cvf PageRank.jar classes;echo classes/*.class; hadoop jar PageRank.jar PageRank
Note: src/PageRank.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: classes/(in = 0) (out= 0)(stored 0%)
adding: classes/NodeOutputFormat.class(in = 1566) (out= 685)(deflated 56%)
adding: classes/PageRank.class(in = 3357) (out= 1789)(deflated 46%)
adding: classes/NodeOrDouble.class(in = 1471) (out= 802)(deflated 45%)
adding: classes/LeftoverReducer.class(in = 1190) (out= 486)(deflated 59%)
adding: classes/TrustMapper.class(in = 1069) (out= 437)(deflated 59%)
adding: classes/NodeRecordReader.class(in = 3117) (out= 1540)(deflated 50%)
adding: classes/NodeInputFormat.class(in = 823) (out= 362)(deflated 56%)
adding: classes/TrustReducer.class(in = 1113) (out= 439)(deflated 60%)
adding: classes/NodeRecordWriter.class(in = 2130) (out= 1150)(deflated 46%)
adding: classes/LeftoverMapper.class(in = 1059) (out= 433)(deflated 59%)
adding: classes/Node.class(in = 2745) (out= 1478)(deflated 46%)
classes/LeftoverMapper.class classes/LeftoverReducer.class classes/Node.class classes/NodeInputFormat.class classes/NodeOrDouble.class classes/NodeOutputFormat.class classes/NodeRecordReader.class classes/NodeRecordWriter.class classes/PageRank.class classes/TrustMapper.class classes/TrustReducer.class
Using input file input/center.txt
16/04/02 18:44:00 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
16/04/02 18:44:00 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
16/04/02 18:44:00 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:00 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:00 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:00 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1937219507_0001
16/04/02 18:44:00 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:00 INFO mapreduce.Job: Running job: job_local1937219507_0001
16/04/02 18:44:00 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:00 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:00 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1937219507_0001_m_000000_0
16/04/02 18:44:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:01 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/input/center.txt:0+54
16/04/02 18:44:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:01 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:01 INFO mapred.LocalJobRunner: 
16/04/02 18:44:01 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:01 INFO mapred.Task: Task:attempt_local1937219507_0001_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:01 INFO mapred.LocalJobRunner: map
16/04/02 18:44:01 INFO mapred.Task: Task 'attempt_local1937219507_0001_m_000000_0' done.
16/04/02 18:44:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1937219507_0001_m_000000_0
16/04/02 18:44:01 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:01 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1937219507_0001_r_000000_0
16/04/02 18:44:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:01 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3098cc00
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:01 INFO reduce.EventFetcher: attempt_local1937219507_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1937219507_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:01 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1937219507_0001_m_000000_0
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:01 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
16/04/02 18:44:01 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:01 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:01 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:01 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:01 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:01 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:01 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
16/04/02 18:44:01 INFO mapred.Task: Task:attempt_local1937219507_0001_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:01 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:01 INFO mapred.Task: Task 'attempt_local1937219507_0001_r_000000_0' done.
16/04/02 18:44:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1937219507_0001_r_000000_0
16/04/02 18:44:01 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:01 INFO mapreduce.Job: Job job_local1937219507_0001 running in uber mode : false
16/04/02 18:44:01 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:01 INFO mapreduce.Job: Job job_local1937219507_0001 completed successfully
16/04/02 18:44:01 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=490
		FILE: Number of bytes written=553196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=311828480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=54
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:01 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:01 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:01 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:01 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:01 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local654848093_0002
16/04/02 18:44:02 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:02 INFO mapreduce.Job: Running job: job_local654848093_0002
16/04/02 18:44:02 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:02 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Starting task: attempt_local654848093_0002_m_000000_0
16/04/02 18:44:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:02 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage0/output.txt:0+0
16/04/02 18:44:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:02 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:02 INFO mapred.LocalJobRunner: 
16/04/02 18:44:02 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:02 INFO mapred.Task: Task:attempt_local654848093_0002_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:02 INFO mapred.LocalJobRunner: map
16/04/02 18:44:02 INFO mapred.Task: Task 'attempt_local654848093_0002_m_000000_0' done.
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local654848093_0002_m_000000_0
16/04/02 18:44:02 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Starting task: attempt_local654848093_0002_r_000000_0
16/04/02 18:44:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:02 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@146a4c90
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:02 INFO reduce.EventFetcher: attempt_local654848093_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:02 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local654848093_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:02 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local654848093_0002_m_000000_0
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:02 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:02 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:02 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:02 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:02 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:02 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
16/04/02 18:44:02 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:02 INFO mapred.Task: Task:attempt_local654848093_0002_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:02 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:02 INFO mapred.Task: Task 'attempt_local654848093_0002_r_000000_0' done.
16/04/02 18:44:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local654848093_0002_r_000000_0
16/04/02 18:44:02 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:03 INFO mapreduce.Job: Job job_local654848093_0002 running in uber mode : false
16/04/02 18:44:03 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:03 INFO mapreduce.Job: Job job_local654848093_0002 completed successfully
16/04/02 18:44:03 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=914
		FILE: Number of bytes written=1103016
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=406200320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:03 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:03 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:03 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:03 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:03 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local723535550_0003
16/04/02 18:44:03 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:03 INFO mapreduce.Job: Running job: job_local723535550_0003
16/04/02 18:44:03 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:03 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Starting task: attempt_local723535550_0003_m_000000_0
16/04/02 18:44:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:03 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage1/output.txt:0+0
16/04/02 18:44:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:03 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:03 INFO mapred.LocalJobRunner: 
16/04/02 18:44:03 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:03 INFO mapred.Task: Task:attempt_local723535550_0003_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:03 INFO mapred.LocalJobRunner: map
16/04/02 18:44:03 INFO mapred.Task: Task 'attempt_local723535550_0003_m_000000_0' done.
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local723535550_0003_m_000000_0
16/04/02 18:44:03 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Starting task: attempt_local723535550_0003_r_000000_0
16/04/02 18:44:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:03 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42e094cc
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:03 INFO reduce.EventFetcher: attempt_local723535550_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:03 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local723535550_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:03 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local723535550_0003_m_000000_0
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:03 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:03 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:03 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:03 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:03 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:03 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:03 INFO mapred.Task: Task:attempt_local723535550_0003_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:03 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:03 INFO mapred.Task: Task 'attempt_local723535550_0003_r_000000_0' done.
16/04/02 18:44:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local723535550_0003_r_000000_0
16/04/02 18:44:03 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:04 INFO mapreduce.Job: Job job_local723535550_0003 running in uber mode : false
16/04/02 18:44:04 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:04 INFO mapreduce.Job: Job job_local723535550_0003 completed successfully
16/04/02 18:44:04 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1338
		FILE: Number of bytes written=1653180
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=40
		Total committed heap usage (bytes)=375791616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:04 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:04 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:04 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:04 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:04 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1460094341_0004
16/04/02 18:44:04 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:04 INFO mapreduce.Job: Running job: job_local1460094341_0004
16/04/02 18:44:04 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:04 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1460094341_0004_m_000000_0
16/04/02 18:44:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:04 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage2/output.txt:0+0
16/04/02 18:44:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:04 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:04 INFO mapred.LocalJobRunner: 
16/04/02 18:44:04 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:04 INFO mapred.Task: Task:attempt_local1460094341_0004_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:04 INFO mapred.LocalJobRunner: map
16/04/02 18:44:04 INFO mapred.Task: Task 'attempt_local1460094341_0004_m_000000_0' done.
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1460094341_0004_m_000000_0
16/04/02 18:44:04 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1460094341_0004_r_000000_0
16/04/02 18:44:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:04 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e4395e1
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:04 INFO reduce.EventFetcher: attempt_local1460094341_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:04 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1460094341_0004_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:04 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1460094341_0004_m_000000_0
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:04 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:04 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:04 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:04 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:04 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:04 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:04 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:04 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:04 INFO mapred.Task: Task:attempt_local1460094341_0004_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:04 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:04 INFO mapred.Task: Task 'attempt_local1460094341_0004_r_000000_0' done.
16/04/02 18:44:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1460094341_0004_r_000000_0
16/04/02 18:44:04 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:05 INFO mapreduce.Job: Job job_local1460094341_0004 running in uber mode : false
16/04/02 18:44:05 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:05 INFO mapreduce.Job: Job job_local1460094341_0004 completed successfully
16/04/02 18:44:05 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1762
		FILE: Number of bytes written=2205996
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=43
		Total committed heap usage (bytes)=475938816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:05 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:05 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:05 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:05 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:05 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1404215071_0005
16/04/02 18:44:05 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:05 INFO mapreduce.Job: Running job: job_local1404215071_0005
16/04/02 18:44:05 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:05 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1404215071_0005_m_000000_0
16/04/02 18:44:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:05 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage3/output.txt:0+0
16/04/02 18:44:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:05 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:05 INFO mapred.LocalJobRunner: 
16/04/02 18:44:05 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:05 INFO mapred.Task: Task:attempt_local1404215071_0005_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:05 INFO mapred.LocalJobRunner: map
16/04/02 18:44:05 INFO mapred.Task: Task 'attempt_local1404215071_0005_m_000000_0' done.
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1404215071_0005_m_000000_0
16/04/02 18:44:05 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1404215071_0005_r_000000_0
16/04/02 18:44:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:05 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@8c5697a
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:05 INFO reduce.EventFetcher: attempt_local1404215071_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:05 INFO reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1404215071_0005_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:05 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1404215071_0005_m_000000_0
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:05 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:05 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:05 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:05 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:05 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:05 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:05 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:05 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:05 INFO mapred.Task: Task:attempt_local1404215071_0005_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:05 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:05 INFO mapred.Task: Task 'attempt_local1404215071_0005_r_000000_0' done.
16/04/02 18:44:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1404215071_0005_r_000000_0
16/04/02 18:44:05 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:06 INFO mapreduce.Job: Job job_local1404215071_0005 running in uber mode : false
16/04/02 18:44:06 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:06 INFO mapreduce.Job: Job job_local1404215071_0005 completed successfully
16/04/02 18:44:06 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2186
		FILE: Number of bytes written=2759164
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=311836672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:06 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:06 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:06 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:06 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:06 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local725493195_0006
16/04/02 18:44:06 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:06 INFO mapreduce.Job: Running job: job_local725493195_0006
16/04/02 18:44:06 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:06 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Starting task: attempt_local725493195_0006_m_000000_0
16/04/02 18:44:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:06 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage4/output.txt:0+0
16/04/02 18:44:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:06 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:06 INFO mapred.LocalJobRunner: 
16/04/02 18:44:06 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:06 INFO mapred.Task: Task:attempt_local725493195_0006_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:06 INFO mapred.LocalJobRunner: map
16/04/02 18:44:06 INFO mapred.Task: Task 'attempt_local725493195_0006_m_000000_0' done.
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local725493195_0006_m_000000_0
16/04/02 18:44:06 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Starting task: attempt_local725493195_0006_r_000000_0
16/04/02 18:44:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:06 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@645bb9b8
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:06 INFO reduce.EventFetcher: attempt_local725493195_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:06 INFO reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local725493195_0006_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:06 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local725493195_0006_m_000000_0
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:06 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:06 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:06 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:06 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:06 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:06 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:06 INFO mapred.Task: Task:attempt_local725493195_0006_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:06 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:06 INFO mapred.Task: Task 'attempt_local725493195_0006_r_000000_0' done.
16/04/02 18:44:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local725493195_0006_r_000000_0
16/04/02 18:44:06 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:07 INFO mapreduce.Job: Job job_local725493195_0006 running in uber mode : false
16/04/02 18:44:07 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:07 INFO mapreduce.Job: Job job_local725493195_0006 completed successfully
16/04/02 18:44:07 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2610
		FILE: Number of bytes written=3308984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=311836672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:07 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:07 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:07 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:07 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:07 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2065284159_0007
16/04/02 18:44:07 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:07 INFO mapreduce.Job: Running job: job_local2065284159_0007
16/04/02 18:44:07 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:07 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Starting task: attempt_local2065284159_0007_m_000000_0
16/04/02 18:44:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:07 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage5/output.txt:0+0
16/04/02 18:44:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:07 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:07 INFO mapred.LocalJobRunner: 
16/04/02 18:44:07 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:07 INFO mapred.Task: Task:attempt_local2065284159_0007_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:07 INFO mapred.LocalJobRunner: map
16/04/02 18:44:07 INFO mapred.Task: Task 'attempt_local2065284159_0007_m_000000_0' done.
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local2065284159_0007_m_000000_0
16/04/02 18:44:07 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Starting task: attempt_local2065284159_0007_r_000000_0
16/04/02 18:44:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:07 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@251a175b
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:07 INFO reduce.EventFetcher: attempt_local2065284159_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:07 INFO reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local2065284159_0007_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:07 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2065284159_0007_m_000000_0
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:07 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:07 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:07 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:07 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:07 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:07 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:07 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:07 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:07 INFO mapred.Task: Task:attempt_local2065284159_0007_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:07 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:07 INFO mapred.Task: Task 'attempt_local2065284159_0007_r_000000_0' done.
16/04/02 18:44:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local2065284159_0007_r_000000_0
16/04/02 18:44:07 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:08 INFO mapreduce.Job: Job job_local2065284159_0007 running in uber mode : false
16/04/02 18:44:08 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:08 INFO mapreduce.Job: Job job_local2065284159_0007 completed successfully
16/04/02 18:44:08 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=3034
		FILE: Number of bytes written=3862152
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=311836672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:08 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:08 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:08 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:08 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:08 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local727669332_0008
16/04/02 18:44:09 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:09 INFO mapreduce.Job: Running job: job_local727669332_0008
16/04/02 18:44:09 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:09 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Starting task: attempt_local727669332_0008_m_000000_0
16/04/02 18:44:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:09 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage6/output.txt:0+0
16/04/02 18:44:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:09 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:09 INFO mapred.LocalJobRunner: 
16/04/02 18:44:09 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:09 INFO mapred.Task: Task:attempt_local727669332_0008_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:09 INFO mapred.LocalJobRunner: map
16/04/02 18:44:09 INFO mapred.Task: Task 'attempt_local727669332_0008_m_000000_0' done.
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local727669332_0008_m_000000_0
16/04/02 18:44:09 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Starting task: attempt_local727669332_0008_r_000000_0
16/04/02 18:44:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:09 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63e6ed16
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:09 INFO reduce.EventFetcher: attempt_local727669332_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:09 INFO reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local727669332_0008_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:09 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local727669332_0008_m_000000_0
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:09 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:09 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:09 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:09 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:09 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:09 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:09 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:09 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:09 INFO mapred.Task: Task:attempt_local727669332_0008_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:09 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:09 INFO mapred.Task: Task 'attempt_local727669332_0008_r_000000_0' done.
16/04/02 18:44:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local727669332_0008_r_000000_0
16/04/02 18:44:09 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/02 18:44:10 INFO mapreduce.Job: Job job_local727669332_0008 running in uber mode : false
16/04/02 18:44:10 INFO mapreduce.Job:  map 100% reduce 100%
16/04/02 18:44:10 INFO mapreduce.Job: Job job_local727669332_0008 completed successfully
16/04/02 18:44:10 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=3458
		FILE: Number of bytes written=4411972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=311836672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
16/04/02 18:44:10 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/02 18:44:10 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/02 18:44:10 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/02 18:44:10 INFO input.FileInputFormat: Total input paths to process : 1
16/04/02 18:44:10 INFO mapreduce.JobSubmitter: number of splits:1
16/04/02 18:44:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1973761509_0009
16/04/02 18:44:10 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/02 18:44:10 INFO mapreduce.Job: Running job: job_local1973761509_0009
16/04/02 18:44:10 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/02 18:44:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:10 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Starting task: attempt_local1973761509_0009_m_000000_0
16/04/02 18:44:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:10 INFO mapred.MapTask: Processing split: file:/home/wei/Wei/DBhw4/skeleton/stage7/output.txt:0+0
16/04/02 18:44:10 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/02 18:44:10 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/02 18:44:10 INFO mapred.MapTask: soft limit at 83886080
16/04/02 18:44:10 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/02 18:44:10 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/02 18:44:10 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/02 18:44:10 INFO mapred.LocalJobRunner: 
16/04/02 18:44:10 INFO mapred.MapTask: Starting flush of map output
16/04/02 18:44:10 INFO mapred.Task: Task:attempt_local1973761509_0009_m_000000_0 is done. And is in the process of committing
16/04/02 18:44:10 INFO mapred.LocalJobRunner: map
16/04/02 18:44:10 INFO mapred.Task: Task 'attempt_local1973761509_0009_m_000000_0' done.
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Finishing task: attempt_local1973761509_0009_m_000000_0
16/04/02 18:44:10 INFO mapred.LocalJobRunner: map task executor complete.
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Starting task: attempt_local1973761509_0009_r_000000_0
16/04/02 18:44:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/02 18:44:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/02 18:44:10 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42eded9
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/02 18:44:10 INFO reduce.EventFetcher: attempt_local1973761509_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/02 18:44:10 INFO reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1973761509_0009_m_000000_0 decomp: 2 len: 6 to MEMORY
16/04/02 18:44:10 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1973761509_0009_m_000000_0
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
16/04/02 18:44:10 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/02 18:44:10 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/02 18:44:10 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:10 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
16/04/02 18:44:10 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/02 18:44:10 INFO mapred.Merger: Merging 1 sorted segments
16/04/02 18:44:10 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
16/04/02 18:44:10 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/02 18:44:10 INFO mapred.Task: Task:attempt_local1973761509_0009_r_000000_0 is done. And is in the process of committing
16/04/02 18:44:10 INFO mapred.LocalJobRunner: reduce > reduce
16/04/02 18:44:10 INFO mapred.Task: Task 'attempt_local1973761509_0009_r_000000_0' done.
16/04/02 18:44:10 INFO mapred.LocalJobRunner: Finishing task: attempt_local1973761509_0009_r_000000_0
16/04/02 18:44:10 INFO mapred.LocalJobRunner: reduce task executor complete.
make: *** [default] Interrupt
